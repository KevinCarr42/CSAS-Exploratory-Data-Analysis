{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:33.467839Z",
     "start_time": "2025-11-19T13:28:32.261408Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "\n",
    "# import file\n",
    "meeting_folder = \"sept_24_coordinators_meeting\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:33.478248Z",
     "start_time": "2025-11-19T13:28:33.467839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_docx_content(file_path):\n",
    "    \"\"\"Extract text from .docx file with structure information.\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    content = []\n",
    "    \n",
    "    for para in doc.paragraphs:\n",
    "        if para.text.strip():\n",
    "            element_type = 'heading' if para.style.name.startswith('Heading') else 'paragraph'\n",
    "            content.append({\n",
    "                'text': para.text,\n",
    "                'element_type': element_type,\n",
    "                'style': para.style.name\n",
    "            })\n",
    "    \n",
    "    if doc.tables:\n",
    "        for table_idx, table in enumerate(doc.tables):\n",
    "            for row_idx, row in enumerate(table.rows):\n",
    "                row_data = [cell.text for cell in row.cells]\n",
    "                content.append({\n",
    "                    'text': ' | '.join(row_data),\n",
    "                    'element_type': 'table_row',\n",
    "                    'style': f'table_{table_idx}_row_{row_idx}'\n",
    "                })\n",
    "    \n",
    "    return content\n",
    "\n",
    "def extract_pptx_content(file_path):\n",
    "    \"\"\"Extract text from .pptx file with slide information.\"\"\"\n",
    "    prs = Presentation(file_path)\n",
    "    content = []\n",
    "    \n",
    "    for slide_idx, slide in enumerate(prs.slides):\n",
    "        for shape_idx, shape in enumerate(slide.shapes):\n",
    "            if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                content.append({\n",
    "                    'text': shape.text,\n",
    "                    'element_type': 'slide_text',\n",
    "                    'style': f'slide_{slide_idx}_shape_{shape_idx}'\n",
    "                })\n",
    "            \n",
    "            if shape.has_table:\n",
    "                table = shape.table\n",
    "                for row_idx, row in enumerate(table.rows):\n",
    "                    row_data = [cell.text for cell in row.cells]\n",
    "                    content.append({\n",
    "                        'text': ' | '.join(row_data),\n",
    "                        'element_type': 'table_row',\n",
    "                        'style': f'slide_{slide_idx}_table_row_{row_idx}'\n",
    "                    })\n",
    "        \n",
    "        if slide.has_notes_slide:\n",
    "            notes_text = slide.notes_slide.notes_text_frame.text\n",
    "            if notes_text.strip():\n",
    "                content.append({\n",
    "                    'text': notes_text,\n",
    "                    'element_type': 'slide_notes',\n",
    "                    'style': f'slide_{slide_idx}_notes'\n",
    "                })\n",
    "    \n",
    "    return content\n",
    "\n",
    "def process_meeting_folder(folder_path):\n",
    "    \"\"\"Process all files in meeting folder and return structured DataFrame.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for file_name in sorted(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        \n",
    "        file_ext = Path(file_path).suffix.lower()\n",
    "        content = []\n",
    "        \n",
    "        if file_ext == '.docx':\n",
    "            content = extract_docx_content(file_path)\n",
    "        elif file_ext == '.pptx':\n",
    "            content = extract_pptx_content(file_path)\n",
    "        \n",
    "        for item in content:\n",
    "            all_data.append({\n",
    "                'source_file': file_name,\n",
    "                'source_type': file_ext,\n",
    "                'text': item['text'],\n",
    "                'element_type': item['element_type'],\n",
    "                'style': item['style'],\n",
    "                'extraction_date': datetime.now().isoformat()\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df"
   ],
   "id": "c3afa8a271cd53b5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 2: Data Parsing",
   "id": "6fa82380a1dc4081"
  },
  {
   "cell_type": "code",
   "id": "wyn0r3j3lkf",
   "source": [
    "print(\"Ensuring correct versions of dependencies...\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"python-docx\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"python-pptx\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langdetect\"])\n",
    "\n",
    "print(\"\\nDependencies installed/upgraded successfully!\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:41.807893Z",
     "start_time": "2025-11-19T13:28:34.417921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring correct versions of dependencies...\n",
      "\n",
      "Dependencies installed/upgraded successfully!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "co32x7dbg2h",
   "source": "## Step 1: Extract text from Word documents",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "vr8o6ipyez8",
   "source": "docx_files = [f for f in os.listdir(meeting_folder) if f.endswith('.docx')]\nprint(f\"Found {len(docx_files)} Word documents:\")\nfor f in docx_files:\n    print(f\"  - {f}\")\n\ndocx_data = []\nfor file_name in docx_files:\n    file_path = os.path.join(meeting_folder, file_name)\n    print(f\"\\nProcessing: {file_name}\")\n    content = extract_docx_content(file_path)\n    print(f\"  Extracted {len(content)} elements\")\n    for item in content:\n        docx_data.append({\n            'source_file': file_name,\n            'source_type': '.docx',\n            'text': item['text'],\n            'element_type': item['element_type'],\n            'style': item['style']\n        })\n\ndf_docx = pd.DataFrame(docx_data)\nprint(f\"\\nTotal DOCX rows: {len(df_docx)}\")\ndf_docx.head(10)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:42.177595Z",
     "start_time": "2025-11-19T13:28:41.811953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 Word documents:\n",
      "  - Centralization of web and publication.docx\n",
      "  - Coordinators F2F Agenda.docx\n",
      "  - F2F Action Items.docx\n",
      "  - F2F Meeting Notes (draft).docx\n",
      "  - F2F Meeting Report (near final).docx\n",
      "  - F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  - Options and best practices for timely publication v2.docx\n",
      "\n",
      "Processing: Centralization of web and publication.docx\n",
      "  Extracted 25 elements\n",
      "\n",
      "Processing: Coordinators F2F Agenda.docx\n",
      "  Extracted 60 elements\n",
      "\n",
      "Processing: F2F Action Items.docx\n",
      "  Extracted 18 elements\n",
      "\n",
      "Processing: F2F Meeting Notes (draft).docx\n",
      "  Extracted 174 elements\n",
      "\n",
      "Processing: F2F Meeting Report (near final).docx\n",
      "  Extracted 173 elements\n",
      "\n",
      "Processing: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  Extracted 173 elements\n",
      "\n",
      "Processing: Options and best practices for timely publication v2.docx\n",
      "  Extracted 47 elements\n",
      "\n",
      "Total DOCX rows: 670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  source_file source_type  \\\n",
       "0  Centralization of web and publication.docx       .docx   \n",
       "1  Centralization of web and publication.docx       .docx   \n",
       "2  Centralization of web and publication.docx       .docx   \n",
       "3  Centralization of web and publication.docx       .docx   \n",
       "4  Centralization of web and publication.docx       .docx   \n",
       "5  Centralization of web and publication.docx       .docx   \n",
       "6  Centralization of web and publication.docx       .docx   \n",
       "7  Centralization of web and publication.docx       .docx   \n",
       "8  Centralization of web and publication.docx       .docx   \n",
       "9  Centralization of web and publication.docx       .docx   \n",
       "\n",
       "                                                                                             text  \\\n",
       "0                                                           Centralization of web and publication   \n",
       "1  Goals: to find efficiencies (time and capacity) in the publication process of the CSAS wheel.    \n",
       "2                        Challenges: As per the 2018 evaluation to reduce publications timelines.   \n",
       "3   Task of the NCR web and pub team (adapted from CSAS Roles and Responsibilities 2015 document)   \n",
       "4                                                           Information management and technology   \n",
       "5                                             Liaise with CDOS on issues related to CSAS database   \n",
       "6                                                         Contribute to modernization of IT Tools   \n",
       "7                                        Management of national shared drive (content and access)   \n",
       "8                                                                         Knowledge dissemination   \n",
       "9                                                                          Publish CSAS documents   \n",
       "\n",
       "  element_type           style  \n",
       "0      heading       Heading 1  \n",
       "1    paragraph          Normal  \n",
       "2    paragraph          Normal  \n",
       "3      heading       Heading 2  \n",
       "4    paragraph  List Paragraph  \n",
       "5    paragraph  List Paragraph  \n",
       "6    paragraph  List Paragraph  \n",
       "7    paragraph  List Paragraph  \n",
       "8    paragraph  List Paragraph  \n",
       "9    paragraph  List Paragraph  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_type</th>\n",
       "      <th>text</th>\n",
       "      <th>element_type</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Centralization of web and publication</td>\n",
       "      <td>heading</td>\n",
       "      <td>Heading 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Goals: to find efficiencies (time and capacity) in the publication process of the CSAS wheel.</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Challenges: As per the 2018 evaluation to reduce publications timelines.</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Task of the NCR web and pub team (adapted from CSAS Roles and Responsibilities 2015 document)</td>\n",
       "      <td>heading</td>\n",
       "      <td>Heading 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Information management and technology</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Liaise with CDOS on issues related to CSAS database</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Contribute to modernization of IT Tools</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Management of national shared drive (content and access)</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Knowledge dissemination</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Publish CSAS documents</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "xsx0axi97y",
   "source": "## Step 2: Extract text from PowerPoint presentations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6gg6nwsr12o",
   "source": "pptx_files = [f for f in os.listdir(meeting_folder) if f.endswith('.pptx')]\nprint(f\"Found {len(pptx_files)} PowerPoint presentations:\")\nfor f in pptx_files:\n    print(f\"  - {f}\")\n\npptx_data = []\nfor file_name in pptx_files:\n    file_path = os.path.join(meeting_folder, file_name)\n    print(f\"\\nProcessing: {file_name}\")\n    content = extract_pptx_content(file_path)\n    print(f\"  Extracted {len(content)} elements\")\n    for item in content:\n        pptx_data.append({\n            'source_file': file_name,\n            'source_type': '.pptx',\n            'text': item['text'],\n            'element_type': item['element_type'],\n            'style': item['style']\n        })\n\ndf_pptx = pd.DataFrame(pptx_data)\nprint(f\"\\nTotal PPTX rows: {len(df_pptx)}\")\ndf_pptx.head(10)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:42.505527Z",
     "start_time": "2025-11-19T13:28:42.207247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PowerPoint presentations:\n",
      "  - CSAS Publications.pptx\n",
      "  - CSAS Transformation update-FR.pptx\n",
      "  - CSAS Transformation update.pptx\n",
      "  - Process vs Product.pptx\n",
      "  - Survival exericise.pptx\n",
      "\n",
      "Processing: CSAS Publications.pptx\n",
      "  Extracted 23 elements\n",
      "\n",
      "Processing: CSAS Transformation update-FR.pptx\n",
      "  Extracted 61 elements\n",
      "\n",
      "Processing: CSAS Transformation update.pptx\n",
      "  Extracted 61 elements\n",
      "\n",
      "Processing: Process vs Product.pptx\n",
      "  Extracted 15 elements\n",
      "\n",
      "Processing: Survival exericise.pptx\n",
      "  Extracted 32 elements\n",
      "\n",
      "Total PPTX rows: 192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              source_file source_type  \\\n",
       "0  CSAS Publications.pptx       .pptx   \n",
       "1  CSAS Publications.pptx       .pptx   \n",
       "2  CSAS Publications.pptx       .pptx   \n",
       "3  CSAS Publications.pptx       .pptx   \n",
       "4  CSAS Publications.pptx       .pptx   \n",
       "5  CSAS Publications.pptx       .pptx   \n",
       "6  CSAS Publications.pptx       .pptx   \n",
       "7  CSAS Publications.pptx       .pptx   \n",
       "8  CSAS Publications.pptx       .pptx   \n",
       "9  CSAS Publications.pptx       .pptx   \n",
       "\n",
       "                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                        CSAS Publications   \n",
       "1                                                                                                                                                            CSAS Coordinators F2F Meeting\\nSeptember 2024   \n",
       "2                                                                                                                                                                                  Objective of Discussion   \n",
       "3  To further explore options for facilitating timely publications\\nTo develop recommendations for the Science Executive Committee (as part of reporting on status of overdue publications)\\n\\n“overdue...   \n",
       "4                                                                                                                                                                                         Review of Status   \n",
       "5                                                                                                                                    Date​ | “Overdue publications”​\\n(from meetings in 2020 and earlier)​   \n",
       "6                                                                                                                                                                                    December 2021​ | 455​   \n",
       "7                                                                                                                                                                                    February 2022​ | 381​   \n",
       "8                                                                                                                                                                                       March 2022​ | 377​   \n",
       "9                                                                                                                                                                                         May 2022​ | 342​   \n",
       "\n",
       "  element_type                style  \n",
       "0   slide_text      slide_0_shape_0  \n",
       "1   slide_text      slide_0_shape_1  \n",
       "2   slide_text      slide_1_shape_0  \n",
       "3   slide_text      slide_1_shape_1  \n",
       "4   slide_text      slide_2_shape_0  \n",
       "5    table_row  slide_2_table_row_0  \n",
       "6    table_row  slide_2_table_row_1  \n",
       "7    table_row  slide_2_table_row_2  \n",
       "8    table_row  slide_2_table_row_3  \n",
       "9    table_row  slide_2_table_row_4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_type</th>\n",
       "      <th>text</th>\n",
       "      <th>element_type</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>CSAS Publications</td>\n",
       "      <td>slide_text</td>\n",
       "      <td>slide_0_shape_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>CSAS Coordinators F2F Meeting\\nSeptember 2024</td>\n",
       "      <td>slide_text</td>\n",
       "      <td>slide_0_shape_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>Objective of Discussion</td>\n",
       "      <td>slide_text</td>\n",
       "      <td>slide_1_shape_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>To further explore options for facilitating timely publications\\nTo develop recommendations for the Science Executive Committee (as part of reporting on status of overdue publications)\\n\\n“overdue...</td>\n",
       "      <td>slide_text</td>\n",
       "      <td>slide_1_shape_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>Review of Status</td>\n",
       "      <td>slide_text</td>\n",
       "      <td>slide_2_shape_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>Date​ | “Overdue publications”​\\n(from meetings in 2020 and earlier)​</td>\n",
       "      <td>table_row</td>\n",
       "      <td>slide_2_table_row_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>December 2021​ | 455​</td>\n",
       "      <td>table_row</td>\n",
       "      <td>slide_2_table_row_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>February 2022​ | 381​</td>\n",
       "      <td>table_row</td>\n",
       "      <td>slide_2_table_row_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>March 2022​ | 377​</td>\n",
       "      <td>table_row</td>\n",
       "      <td>slide_2_table_row_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CSAS Publications.pptx</td>\n",
       "      <td>.pptx</td>\n",
       "      <td>May 2022​ | 342​</td>\n",
       "      <td>table_row</td>\n",
       "      <td>slide_2_table_row_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7tn5st4jv3m",
   "source": "## Step 3: Combine into master DataFrame",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yj9suz3qap",
   "source": "df_raw = pd.concat([df_docx, df_pptx], ignore_index=True)\nprint(f\"Combined raw extraction: {len(df_raw)} total rows\")\nprint(f\"\\nBreakdown by source type:\")\nprint(df_raw['source_type'].value_counts())\nprint(f\"\\nBreakdown by element type:\")\nprint(df_raw['element_type'].value_counts())\n\n# Add index for tracking\ndf_raw.insert(0, 'row_id', range(1, len(df_raw) + 1))\n\nprint(f\"\\nFirst 10 rows:\")\ndf_raw.head(10)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:42.540760Z",
     "start_time": "2025-11-19T13:28:42.530993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined raw extraction: 862 total rows\n",
      "\n",
      "Breakdown by source type:\n",
      "source_type\n",
      ".docx    670\n",
      ".pptx    192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Breakdown by element type:\n",
      "element_type\n",
      "paragraph      421\n",
      "table_row      295\n",
      "slide_text     120\n",
      "heading         23\n",
      "slide_notes      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   row_id                                 source_file source_type  \\\n",
       "0       1  Centralization of web and publication.docx       .docx   \n",
       "1       2  Centralization of web and publication.docx       .docx   \n",
       "2       3  Centralization of web and publication.docx       .docx   \n",
       "3       4  Centralization of web and publication.docx       .docx   \n",
       "4       5  Centralization of web and publication.docx       .docx   \n",
       "5       6  Centralization of web and publication.docx       .docx   \n",
       "6       7  Centralization of web and publication.docx       .docx   \n",
       "7       8  Centralization of web and publication.docx       .docx   \n",
       "8       9  Centralization of web and publication.docx       .docx   \n",
       "9      10  Centralization of web and publication.docx       .docx   \n",
       "\n",
       "                                                                                             text  \\\n",
       "0                                                           Centralization of web and publication   \n",
       "1  Goals: to find efficiencies (time and capacity) in the publication process of the CSAS wheel.    \n",
       "2                        Challenges: As per the 2018 evaluation to reduce publications timelines.   \n",
       "3   Task of the NCR web and pub team (adapted from CSAS Roles and Responsibilities 2015 document)   \n",
       "4                                                           Information management and technology   \n",
       "5                                             Liaise with CDOS on issues related to CSAS database   \n",
       "6                                                         Contribute to modernization of IT Tools   \n",
       "7                                        Management of national shared drive (content and access)   \n",
       "8                                                                         Knowledge dissemination   \n",
       "9                                                                          Publish CSAS documents   \n",
       "\n",
       "  element_type           style  \n",
       "0      heading       Heading 1  \n",
       "1    paragraph          Normal  \n",
       "2    paragraph          Normal  \n",
       "3      heading       Heading 2  \n",
       "4    paragraph  List Paragraph  \n",
       "5    paragraph  List Paragraph  \n",
       "6    paragraph  List Paragraph  \n",
       "7    paragraph  List Paragraph  \n",
       "8    paragraph  List Paragraph  \n",
       "9    paragraph  List Paragraph  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_type</th>\n",
       "      <th>text</th>\n",
       "      <th>element_type</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Centralization of web and publication</td>\n",
       "      <td>heading</td>\n",
       "      <td>Heading 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Goals: to find efficiencies (time and capacity) in the publication process of the CSAS wheel.</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Challenges: As per the 2018 evaluation to reduce publications timelines.</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Task of the NCR web and pub team (adapted from CSAS Roles and Responsibilities 2015 document)</td>\n",
       "      <td>heading</td>\n",
       "      <td>Heading 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Information management and technology</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Liaise with CDOS on issues related to CSAS database</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Contribute to modernization of IT Tools</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Management of national shared drive (content and access)</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Knowledge dissemination</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Centralization of web and publication.docx</td>\n",
       "      <td>.docx</td>\n",
       "      <td>Publish CSAS documents</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>List Paragraph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "rzc2qq8cf9t",
   "source": "## Step 4: Validate extraction quality",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "o4iil9y7htf",
   "source": "print(\"=== EXTRACTION QUALITY ASSESSMENT ===\\n\")\n\nprint(f\"Total rows extracted: {len(df_raw)}\")\nprint(f\"Total characters: {df_raw['text'].str.len().sum():,}\")\nprint(f\"Average text length per row: {df_raw['text'].str.len().mean():.1f} chars\")\n\nprint(f\"\\n--- Null values ---\")\nprint(df_raw.isnull().sum())\n\nprint(f\"\\n--- Text length distribution ---\")\nprint(df_raw['text'].str.len().describe())\n\nprint(f\"\\n--- Files processed ---\")\nfor source_file in sorted(df_raw['source_file'].unique()):\n    count = len(df_raw[df_raw['source_file'] == source_file])\n    total_chars = df_raw[df_raw['source_file'] == source_file]['text'].str.len().sum()\n    print(f\"  {source_file:<60} {count:>4} rows  {total_chars:>8,} chars\")\n\nprint(f\"\\n--- Element types extracted ---\")\nfor elem_type in sorted(df_raw['element_type'].unique()):\n    count = len(df_raw[df_raw['element_type'] == elem_type])\n    print(f\"  {elem_type:<30} {count:>4} rows\")\n\nprint(\"\\nExtraction completed successfully!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:42.758118Z",
     "start_time": "2025-11-19T13:28:42.743072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXTRACTION QUALITY ASSESSMENT ===\n",
      "\n",
      "Total rows extracted: 862\n",
      "Total characters: 103,971\n",
      "Average text length per row: 120.6 chars\n",
      "\n",
      "--- Null values ---\n",
      "row_id          0\n",
      "source_file     0\n",
      "source_type     0\n",
      "text            0\n",
      "element_type    0\n",
      "style           0\n",
      "dtype: int64\n",
      "\n",
      "--- Text length distribution ---\n",
      "count   862.0\n",
      "mean    120.6\n",
      "std     135.0\n",
      "min       1.0\n",
      "25%      28.0\n",
      "50%      72.0\n",
      "75%     161.5\n",
      "max     865.0\n",
      "Name: text, dtype: float64\n",
      "\n",
      "--- Files processed ---\n",
      "  CSAS Publications.pptx                                         23 rows     1,665 chars\n",
      "  CSAS Transformation update-FR.pptx                             61 rows     7,141 chars\n",
      "  CSAS Transformation update.pptx                                61 rows     5,561 chars\n",
      "  Centralization of web and publication.docx                     25 rows     2,662 chars\n",
      "  Coordinators F2F Agenda.docx                                   60 rows     5,478 chars\n",
      "  F2F Action Items.docx                                          18 rows       470 chars\n",
      "  F2F Meeting Notes (draft).docx                                174 rows    19,437 chars\n",
      "  F2F Meeting Report (near final).docx                          173 rows    19,742 chars\n",
      "  F2F Meeting Report (near final)_TG_FR_LS_Final.docx           173 rows    26,434 chars\n",
      "  Options and best practices for timely publication v2.docx      47 rows     7,272 chars\n",
      "  Process vs Product.pptx                                        15 rows     3,758 chars\n",
      "  Survival exericise.pptx                                        32 rows     4,351 chars\n",
      "\n",
      "--- Element types extracted ---\n",
      "  heading                          23 rows\n",
      "  paragraph                       421 rows\n",
      "  slide_notes                       3 rows\n",
      "  slide_text                      120 rows\n",
      "  table_row                       295 rows\n",
      "\n",
      "Extraction completed successfully!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "0p77yvcvvo1f",
   "source": "## Phase 3: Data Cleaning & Normalization",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "kyoxkhdfc5d",
   "source": "### Step 1: Add language detection",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p7fwf593lce",
   "source": [
    "def detect_language(text):\n",
    "    if not text or len(text.strip()) < 3:\n",
    "        return 'unknown'\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "df_clean = df_raw.copy()\n",
    "df_clean['language'] = df_clean['text'].apply(detect_language)\n",
    "\n",
    "print(\"Language detection completed.\")\n",
    "print(f\"\\nLanguage distribution:\")\n",
    "print(df_clean['language'].value_counts())\n",
    "\n",
    "print(f\"\\n--- Language by source file ---\")\n",
    "lang_summary = df_clean.groupby(['source_file', 'language']).size().unstack(fill_value=0)\n",
    "print(lang_summary)\n",
    "\n",
    "print(f\"\\n--- Top rows by language (en=English, fr=French, other) ---\")\n",
    "for lang in sorted(df_clean['language'].unique()):\n",
    "    sample = df_clean[df_clean['language'] == lang].head(3)\n",
    "    print(f\"\\n{lang.upper()}:\")\n",
    "    for idx, row in sample.iterrows():\n",
    "        print(f\"  [{row['source_file']}] {row['text'][:80]}...\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:46.763552Z",
     "start_time": "2025-11-19T13:28:42.979890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language detection completed.\n",
      "\n",
      "Language distribution:\n",
      "language\n",
      "en         493\n",
      "fr         227\n",
      "de          35\n",
      "unknown     30\n",
      "tl          20\n",
      "ca          11\n",
      "it          10\n",
      "nl           5\n",
      "sw           4\n",
      "ro           4\n",
      "pt           4\n",
      "so           3\n",
      "hu           3\n",
      "id           3\n",
      "vi           2\n",
      "af           2\n",
      "es           1\n",
      "sv           1\n",
      "fi           1\n",
      "no           1\n",
      "hr           1\n",
      "cy           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Language by source file ---\n",
      "language                                                   af  ca  cy  de  \\\n",
      "source_file                                                                 \n",
      "CSAS Publications.pptx                                      0   0   0   2   \n",
      "CSAS Transformation update-FR.pptx                          0   1   0   0   \n",
      "CSAS Transformation update.pptx                             0   0   0   0   \n",
      "Centralization of web and publication.docx                  0   0   0   0   \n",
      "Coordinators F2F Agenda.docx                                0   0   0   7   \n",
      "F2F Action Items.docx                                       0   0   0   1   \n",
      "F2F Meeting Notes (draft).docx                              1   2   0   8   \n",
      "F2F Meeting Report (near final).docx                        1   3   0   8   \n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx         0   4   0   8   \n",
      "Options and best practices for timely publication v2.docx   0   0   0   1   \n",
      "Process vs Product.pptx                                     0   0   0   0   \n",
      "Survival exericise.pptx                                     0   1   1   0   \n",
      "\n",
      "language                                                    en  es  fi   fr  \\\n",
      "source_file                                                                   \n",
      "CSAS Publications.pptx                                      15   0   0    2   \n",
      "CSAS Transformation update-FR.pptx                           8   0   0   37   \n",
      "CSAS Transformation update.pptx                             43   0   0    0   \n",
      "Centralization of web and publication.docx                  24   0   0    1   \n",
      "Coordinators F2F Agenda.docx                                22   0   0   21   \n",
      "F2F Action Items.docx                                       13   1   0    0   \n",
      "F2F Meeting Notes (draft).docx                             147   0   0    1   \n",
      "F2F Meeting Report (near final).docx                       146   0   0    0   \n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx          3   0   0  147   \n",
      "Options and best practices for timely publication v2.docx   43   0   1    2   \n",
      "Process vs Product.pptx                                     15   0   0    0   \n",
      "Survival exericise.pptx                                     14   0   0   16   \n",
      "\n",
      "language                                                   hr  hu  id  it  nl  \\\n",
      "source_file                                                                     \n",
      "CSAS Publications.pptx                                      0   0   0   0   1   \n",
      "CSAS Transformation update-FR.pptx                          0   0   0   0   0   \n",
      "CSAS Transformation update.pptx                             1   0   0   1   0   \n",
      "Centralization of web and publication.docx                  0   0   0   0   0   \n",
      "Coordinators F2F Agenda.docx                                0   0   1   0   2   \n",
      "F2F Action Items.docx                                       0   0   0   1   0   \n",
      "F2F Meeting Notes (draft).docx                              0   1   1   3   1   \n",
      "F2F Meeting Report (near final).docx                        0   1   1   3   1   \n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx         0   1   0   2   0   \n",
      "Options and best practices for timely publication v2.docx   0   0   0   0   0   \n",
      "Process vs Product.pptx                                     0   0   0   0   0   \n",
      "Survival exericise.pptx                                     0   0   0   0   0   \n",
      "\n",
      "language                                                   no  pt  ro  so  sv  \\\n",
      "source_file                                                                     \n",
      "CSAS Publications.pptx                                      1   0   1   0   0   \n",
      "CSAS Transformation update-FR.pptx                          0   0   0   0   0   \n",
      "CSAS Transformation update.pptx                             0   0   0   1   0   \n",
      "Centralization of web and publication.docx                  0   0   0   0   0   \n",
      "Coordinators F2F Agenda.docx                                0   0   1   0   0   \n",
      "F2F Action Items.docx                                       0   0   0   0   0   \n",
      "F2F Meeting Notes (draft).docx                              0   1   0   0   0   \n",
      "F2F Meeting Report (near final).docx                        0   1   0   0   0   \n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx         0   2   2   2   1   \n",
      "Options and best practices for timely publication v2.docx   0   0   0   0   0   \n",
      "Process vs Product.pptx                                     0   0   0   0   0   \n",
      "Survival exericise.pptx                                     0   0   0   0   0   \n",
      "\n",
      "language                                                   sw  tl  unknown  vi  \n",
      "source_file                                                                     \n",
      "CSAS Publications.pptx                                      0   1        0   0  \n",
      "CSAS Transformation update-FR.pptx                          0   0       15   0  \n",
      "CSAS Transformation update.pptx                             0   0       15   0  \n",
      "Centralization of web and publication.docx                  0   0        0   0  \n",
      "Coordinators F2F Agenda.docx                                4   2        0   0  \n",
      "F2F Action Items.docx                                       0   2        0   0  \n",
      "F2F Meeting Notes (draft).docx                              0   7        0   1  \n",
      "F2F Meeting Report (near final).docx                        0   7        0   1  \n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx         0   1        0   0  \n",
      "Options and best practices for timely publication v2.docx   0   0        0   0  \n",
      "Process vs Product.pptx                                     0   0        0   0  \n",
      "Survival exericise.pptx                                     0   0        0   0  \n",
      "\n",
      "--- Top rows by language (en=English, fr=French, other) ---\n",
      "\n",
      "AF:\n",
      "  [F2F Meeting Notes (draft).docx] Overview...\n",
      "  [F2F Meeting Report (near final).docx] Overview...\n",
      "\n",
      "CA:\n",
      "  [F2F Meeting Notes (draft).docx] Participants...\n",
      "  [F2F Meeting Notes (draft).docx] Alexandra Merkx-Jacques | CSAS-IA National Capital Region...\n",
      "  [F2F Meeting Report (near final).docx] Participants...\n",
      "\n",
      "CY:\n",
      "  [Survival exericise.pptx] How well did you do?...\n",
      "\n",
      "DE:\n",
      "  [Coordinators F2F Agenda.docx] September 17-18, 2024...\n",
      "  [Coordinators F2F Agenda.docx] September 17-18, 2024...\n",
      "  [Coordinators F2F Agenda.docx] DAY 2: Wednesday, September 18 ...\n",
      "\n",
      "EN:\n",
      "  [Centralization of web and publication.docx] Centralization of web and publication...\n",
      "  [Centralization of web and publication.docx] Goals: to find efficiencies (time and capacity) in the publication process of th...\n",
      "  [Centralization of web and publication.docx] Challenges: As per the 2018 evaluation to reduce publications timelines....\n",
      "\n",
      "ES:\n",
      "  [F2F Action Items.docx] Guidance:...\n",
      "\n",
      "FI:\n",
      "  [Options and best practices for timely publication v2.docx] Solution?...\n",
      "\n",
      "FR:\n",
      "  [Centralization of web and publication.docx] Update publication database management system...\n",
      "  [Coordinators F2F Agenda.docx] Réunion des coordonnateurs du SCAS...\n",
      "  [Coordinators F2F Agenda.docx] 17 et 18 septembre 2024...\n",
      "\n",
      "HR:\n",
      "  [CSAS Transformation update.pptx] Objective \u000B...\n",
      "\n",
      "HU:\n",
      "  [F2F Meeting Notes (draft).docx] ANNEX A:...\n",
      "  [F2F Meeting Report (near final).docx] ANNEX A:...\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] ANNEXE A :...\n",
      "\n",
      "ID:\n",
      "  [Coordinators F2F Agenda.docx] JOUR 1 : Mardi 17 septembre...\n",
      "  [F2F Meeting Notes (draft).docx] Data...\n",
      "  [F2F Meeting Report (near final).docx] Data...\n",
      "\n",
      "IT:\n",
      "  [F2F Action Items.docx] Reconciliation:...\n",
      "  [F2F Meeting Notes (draft).docx] Lisa Setterington | CSAS National Capital Region...\n",
      "  [F2F Meeting Notes (draft).docx] Mark Laflamme | Open Science National Capital Region...\n",
      "\n",
      "NL:\n",
      "  [Coordinators F2F Agenda.docx] 222 Nepean Street (Boardroom 1022)...\n",
      "  [Coordinators F2F Agenda.docx] 222 Nepean Street (Boardroom 1022)...\n",
      "  [F2F Meeting Notes (draft).docx] Engagement...\n",
      "\n",
      "NO:\n",
      "  [CSAS Publications.pptx] November 2022​ | 273​...\n",
      "\n",
      "PT:\n",
      "  [F2F Meeting Notes (draft).docx] Miriam O | CSAS Pacific...\n",
      "  [F2F Meeting Report (near final).docx] Miriam O | CSAS Pacific...\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] ÉTAPE | DÉLAI PROPOSÉ...\n",
      "\n",
      "RO:\n",
      "  [Coordinators F2F Agenda.docx] JOUR 2 : Mercredi 18 septembre ...\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] ANNEXE B (suite) :...\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] JOUR 2 : Mercredi 18 septembre ...\n",
      "\n",
      "SO:\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] MESURE :...\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] QUESTION RESTÉE EN SUSPENS : ...\n",
      "  [CSAS Transformation update.pptx] Thank you \n",
      "\n",
      "\n",
      "QUESTIONS?\n",
      "...\n",
      "\n",
      "SV:\n",
      "  [F2F Meeting Report (near final)_TG_FR_LS_Final.docx] Hybride (Ottawa et MS Teams)...\n",
      "\n",
      "SW:\n",
      "  [Coordinators F2F Agenda.docx] Ottawa...\n",
      "  [Coordinators F2F Agenda.docx] Ottawa...\n",
      "  [Coordinators F2F Agenda.docx] Ottawa...\n",
      "\n",
      "TL:\n",
      "  [Coordinators F2F Agenda.docx] AGENDA...\n",
      "  [Coordinators F2F Agenda.docx] AGENDA...\n",
      "  [F2F Action Items.docx] Engaging Experts:...\n",
      "\n",
      "UNKNOWN:\n",
      "  [CSAS Transformation update-FR.pptx] 1...\n",
      "  [CSAS Transformation update-FR.pptx] 2...\n",
      "  [CSAS Transformation update-FR.pptx] 3...\n",
      "\n",
      "VI:\n",
      "  [F2F Meeting Notes (draft).docx] PARKING LOT: ...\n",
      "  [F2F Meeting Report (near final).docx] PARKING LOT: ...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "g6ewlmna0cd",
   "source": "### Step 2: Identify duplicate and near-duplicate content",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "m1615pdlefr",
   "source": [
    "def similarity_ratio(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "print(\"=== DUPLICATE AND NEAR-DUPLICATE ANALYSIS ===\\n\")\n",
    "\n",
    "# Check exact duplicates\n",
    "exact_dups = df_clean[df_clean.duplicated(subset=['text'], keep=False)].sort_values('text')\n",
    "print(f\"Exact duplicate rows: {len(exact_dups)}\")\n",
    "if len(exact_dups) > 0:\n",
    "    print(\"Exact duplicates found:\")\n",
    "    for text in exact_dups['text'].unique():\n",
    "        sources = df_clean[df_clean['text'] == text]['source_file'].unique()\n",
    "        print(f\"  Text appears in: {sources}\")\n",
    "\n",
    "# Known pairs to check: F2F Meeting Report versions and Transformation presentations\n",
    "print(\"\\n--- Known document pairs (for manual review) ---\")\n",
    "print(\"1. F2F Meeting Report (near final).docx vs (near final)_TG_FR_LS_Final.docx\")\n",
    "f2f_1 = df_clean[df_clean['source_file'] == 'F2F Meeting Report (near final).docx']\n",
    "f2f_2 = df_clean[df_clean['source_file'] == 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
    "print(f\"   First version: {len(f2f_1)} rows, Second version: {len(f2f_2)} rows\")\n",
    "\n",
    "print(\"\\n2. CSAS Transformation update.pptx (EN) vs (FR)\")\n",
    "trans_en = df_clean[df_clean['source_file'] == 'CSAS Transformation update.pptx']\n",
    "trans_fr = df_clean[df_clean['source_file'] == 'CSAS Transformation update-FR.pptx']\n",
    "print(f\"   English: {len(trans_en)} rows, French: {len(trans_fr)} rows\")\n",
    "print(f\"   (Both likely contain same content in different languages)\")\n",
    "\n",
    "# Sample of potential near-duplicates across reports\n",
    "print(\"\\n--- Checking for near-duplicates across meeting report documents ---\")\n",
    "meeting_reports = df_clean[df_clean['source_file'].str.contains('F2F Meeting Report')]\n",
    "for idx, (i, row1) in enumerate(meeting_reports.iterrows()):\n",
    "    for j, row2 in meeting_reports.iloc[idx+1:].iterrows():\n",
    "        if len(row1['text']) > 20 and len(row2['text']) > 20:\n",
    "            sim = similarity_ratio(row1['text'], row2['text'])\n",
    "            if sim > 0.95:\n",
    "                print(f\"  High similarity (95%+) between documents\")\n",
    "                print(f\"    File 1: {row1['source_file']}\")\n",
    "                print(f\"    File 2: {row2['source_file']}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:57.846335Z",
     "start_time": "2025-11-19T13:28:46.864163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DUPLICATE AND NEAR-DUPLICATE ANALYSIS ===\n",
      "\n",
      "Exact duplicate rows: 442\n",
      "Exact duplicates found:\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx'\n",
      " 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx'\n",
      " 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx'\n",
      " 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx'\n",
      " 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Process vs Product.pptx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx'\n",
      " 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx'\n",
      " 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['Coordinators F2F Agenda.docx' 'F2F Meeting Notes (draft).docx'\n",
      " 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['CSAS Transformation update-FR.pptx' 'CSAS Transformation update.pptx']\n",
      "  Text appears in: ['F2F Meeting Report (near final)_TG_FR_LS_Final.docx'\n",
      " 'CSAS Transformation update-FR.pptx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Report (near final)_TG_FR_LS_Final.docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "  Text appears in: ['F2F Meeting Notes (draft).docx' 'F2F Meeting Report (near final).docx']\n",
      "\n",
      "--- Known document pairs (for manual review) ---\n",
      "1. F2F Meeting Report (near final).docx vs (near final)_TG_FR_LS_Final.docx\n",
      "   First version: 173 rows, Second version: 173 rows\n",
      "\n",
      "2. CSAS Transformation update.pptx (EN) vs (FR)\n",
      "   English: 61 rows, French: 61 rows\n",
      "   (Both likely contain same content in different languages)\n",
      "\n",
      "--- Checking for near-duplicates across meeting report documents ---\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final).docx\n",
      "    File 2: F2F Meeting Report (near final).docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final).docx\n",
      "    File 2: F2F Meeting Report (near final).docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final).docx\n",
      "    File 2: F2F Meeting Report (near final).docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final).docx\n",
      "    File 2: F2F Meeting Report (near final).docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final).docx\n",
      "    File 2: F2F Meeting Report (near final).docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  High similarity (95%+) between documents\n",
      "    File 1: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "    File 2: F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "0dvncd6p1fve",
   "source": "### Step 3: Extract action items and keywords",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jcie28yo9v",
   "source": [
    "\n",
    "\n",
    "action_keywords = [\n",
    "    'action item', 'action:', 'to do', 'todo:', 'task:', 'deliver',\n",
    "    'responsibility', 'owner:', 'by:', 'deadline', 'date:', \n",
    "    'follow-up', 'follow up', 'next step', 'will', 'should',\n",
    "    'needs to', 'required', 'must', 'implement', 'complete'\n",
    "]\n",
    "\n",
    "recommendation_keywords = [\n",
    "    'recommendation', 'recommend', 'suggest', 'propose', 'best practice',\n",
    "    'option', 'approach', 'consideration', 'should consider'\n",
    "]\n",
    "\n",
    "contention_keywords = [\n",
    "    'concern', 'issue', 'challenge', 'problem', 'risk', 'conflict',\n",
    "    'disagreement', 'debate', 'discuss', 'decision needed',\n",
    "    'pending', 'unclear', 'undefined'\n",
    "]\n",
    "\n",
    "def check_content_type(text, keyword_list):\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in keyword_list)\n",
    "\n",
    "df_clean['is_action_item'] = df_clean['text'].apply(\n",
    "    lambda x: check_content_type(x, action_keywords)\n",
    ")\n",
    "df_clean['is_recommendation'] = df_clean['text'].apply(\n",
    "    lambda x: check_content_type(x, recommendation_keywords)\n",
    ")\n",
    "df_clean['is_contention'] = df_clean['text'].apply(\n",
    "    lambda x: check_content_type(x, contention_keywords)\n",
    ")\n",
    "\n",
    "print(\"=== CONTENT CATEGORIZATION ===\\n\")\n",
    "print(f\"Action items identified: {df_clean['is_action_item'].sum()}\")\n",
    "print(f\"Recommendations identified: {df_clean['is_recommendation'].sum()}\")\n",
    "print(f\"Contentious/issue items: {df_clean['is_contention'].sum()}\")\n",
    "\n",
    "print(\"\\n--- Sample Action Items ---\")\n",
    "action_samples = df_clean[df_clean['is_action_item']].head(10)\n",
    "for idx, row in action_samples.iterrows():\n",
    "    print(f\"[{row['source_file']}] {row['text'][:100]}\")\n",
    "\n",
    "print(\"\\n--- Sample Recommendations ---\")\n",
    "rec_samples = df_clean[df_clean['is_recommendation']].head(10)\n",
    "for idx, row in rec_samples.iterrows():\n",
    "    print(f\"[{row['source_file']}] {row['text'][:100]}\")\n",
    "\n",
    "print(\"\\n--- Sample Contentious Items ---\")\n",
    "cont_samples = df_clean[df_clean['is_contention']].head(10)\n",
    "for idx, row in cont_samples.iterrows():\n",
    "    print(f\"[{row['source_file']}] {row['text'][:100]}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:57.882678Z",
     "start_time": "2025-11-19T13:28:57.868037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONTENT CATEGORIZATION ===\n",
      "\n",
      "Action items identified: 129\n",
      "Recommendations identified: 66\n",
      "Contentious/issue items: 124\n",
      "\n",
      "--- Sample Action Items ---\n",
      "[Centralization of web and publication.docx] Develop and implement national web publication guidelines, processes, and templates\n",
      "[Centralization of web and publication.docx] Ensure online calendar is up to date: update CSAS calendar Code and post CSAS documents (Terms of Re\n",
      "[Centralization of web and publication.docx] To build relationships and improve quality of translations, web and pub team should scan and verify \n",
      "[Centralization of web and publication.docx] Hire “Finalizer” in the NCR web and pub team. Regions with finalizers have lost these people and pos\n",
      "[Coordinators F2F Agenda.docx] 10:00 to 11:00 | CSAS Transformation\n",
      "Objective: \n",
      "to share updates on Transformation \n",
      "to seek input o\n",
      "[Coordinators F2F Agenda.docx] 11:00 to 12:00 | CSAS DM App Needs Assessment – \n",
      "Phase I (Requests for Advice)\n",
      "Objective:\n",
      "to review \n",
      "[Coordinators F2F Agenda.docx] 1:00 to 2:15 | CSAS DM App Needs Assessment – \n",
      "Phase I\n",
      "Next steps for app\n",
      " | Presenter: Mark\n",
      "Note ta\n",
      "[Coordinators F2F Agenda.docx] 2:15 to 3:15 | Publications\n",
      "Objective:\n",
      "to further explore options for ensuring timely publications (\n",
      "[Coordinators F2F Agenda.docx] 3:30 to 4:30 | Action items and Next Steps\n",
      "Objective: \n",
      "to review action items\n",
      "to identify topics for\n",
      "[F2F Action Items.docx] CSAS Transformation: F2F Action Items by ‘theme’ \n",
      "\n",
      "--- Sample Recommendations ---\n",
      "[Centralization of web and publication.docx] Hire “Finalizer” in the NCR web and pub team. Regions with finalizers have lost these people and pos\n",
      "[Coordinators F2F Agenda.docx] 2:15 to 3:15 | Publications\n",
      "Objective:\n",
      "to further explore options for ensuring timely publications (\n",
      "[Coordinators F2F Agenda.docx] 13 h – 14 h 15 | Publications\n",
      "Objectif :\n",
      "explorer davantage les options pour s’assurer d’avoir des p\n",
      "[F2F Meeting Notes (draft).docx] ACTION: NCR CSAS to include the above considerations in guidance document.\n",
      "[F2F Meeting Notes (draft).docx] Coordinators suggested a change in language.  There is only one template, so we do not need to refer\n",
      "[F2F Meeting Notes (draft).docx] This is an optional section. We will use case-studies to see how to implement during a desk-top exer\n",
      "[F2F Meeting Notes (draft).docx] Coordinators suggested that this may not be a policy, and rather this element could be considered in\n",
      "[F2F Meeting Notes (draft).docx] ACTION: NCR CSAS to consider embedding this new approach within a “transparency” policy.\t\n",
      "[F2F Meeting Notes (draft).docx] PARKING LOT: discussion about different regional approach related to logos; criteria for determining\n",
      "[F2F Meeting Notes (draft).docx] Joclyn outlined considerations when determining whether a CSAS process is required. These include:\n",
      "\n",
      "--- Sample Contentious Items ---\n",
      "[Centralization of web and publication.docx] Challenges: As per the 2018 evaluation to reduce publications timelines.\n",
      "[Centralization of web and publication.docx] Liaise with CDOS on issues related to CSAS database\n",
      "[Centralization of web and publication.docx] Hire “Finalizer” in the NCR web and pub team. Regions with finalizers have lost these people and pos\n",
      "[Coordinators F2F Agenda.docx] 2:15 to 3:15 | Publications\n",
      "Objective:\n",
      "to further explore options for ensuring timely publications (\n",
      "[Coordinators F2F Agenda.docx] 13 h – 14 h 15 | Publications\n",
      "Objectif :\n",
      "explorer davantage les options pour s’assurer d’avoir des p\n",
      "[F2F Meeting Notes (draft).docx] The meeting notes below summarize main discussion topics and identify action items and “Parking Lot”\n",
      "[F2F Meeting Notes (draft).docx] With the objective of sharing updates on CSAS Transformation and seek input on next steps, Lushani p\n",
      "[F2F Meeting Notes (draft).docx] Discussion focused on SAR and SRRs as products and whether processes lead to specific products.  Det\n",
      "[F2F Meeting Notes (draft).docx] ACTION: “What we heard” discussion at weekly CSAS Coordinators meeting.\n",
      "[F2F Meeting Notes (draft).docx] ACTION: use a weekly CSAS Coordinators meeting to walk through the F-SAR template section by section\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "wnlqygagin",
   "source": "### Step 4: Normalize text and generate summary statistics",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5elgpxk321n",
   "source": "def normalize_text(text):\n    text = text.strip()\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\ndf_clean['text_normalized'] = df_clean['text'].apply(normalize_text)\n\nprint(\"=== TEXT NORMALIZATION & CLEANING SUMMARY ===\\n\")\n\n# Check for empty/very short entries after normalization\nshort_entries = df_clean[df_clean['text_normalized'].str.len() < 5]\nprint(f\"Very short entries (<5 chars): {len(short_entries)}\")\n\n# Check for common formatting issues\nprint(f\"\\nFormatting checks:\")\nprint(f\"  Entries with multiple spaces normalized: {(df_clean['text'] != df_clean['text_normalized']).sum()}\")\n\n# Summary by document\nprint(\"\\n--- Summary Statistics by Source File ---\")\nsummary_stats = df_clean.groupby('source_file').agg({\n    'row_id': 'count',\n    'language': lambda x: x.value_counts().to_dict(),\n    'is_action_item': 'sum',\n    'is_recommendation': 'sum',\n    'is_contention': 'sum'\n}).rename(columns={'row_id': 'total_rows'})\n\nfor source_file in sorted(df_clean['source_file'].unique()):\n    subset = df_clean[df_clean['source_file'] == source_file]\n    total = len(subset)\n    lang_dist = subset['language'].value_counts().to_dict()\n    actions = subset['is_action_item'].sum()\n    recs = subset['is_recommendation'].sum()\n    contents = subset['is_contention'].sum()\n    \n    print(f\"\\n{source_file}\")\n    print(f\"  Total rows: {total}\")\n    print(f\"  Languages: {lang_dist}\")\n    print(f\"  Action items: {actions}, Recommendations: {recs}, Contentions: {contents}\")\n\n# Export cleaned data for next phase\ndf_clean.to_pickle('meeting_data_cleaned.pkl')\ndf_clean.to_csv('meeting_data_cleaned.csv', index=False)\nprint(\"\\n\\nCleaned data saved to meeting_data_cleaned.pkl and meeting_data_cleaned.csv\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:28:58.001006Z",
     "start_time": "2025-11-19T13:28:57.968804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXT NORMALIZATION & CLEANING SUMMARY ===\n",
      "\n",
      "Very short entries (<5 chars): 32\n",
      "\n",
      "Formatting checks:\n",
      "  Entries with multiple spaces normalized: 425\n",
      "\n",
      "--- Summary Statistics by Source File ---\n",
      "\n",
      "CSAS Publications.pptx\n",
      "  Total rows: 23\n",
      "  Languages: {'en': 15, 'de': 2, 'fr': 2, 'nl': 1, 'tl': 1, 'no': 1, 'ro': 1}\n",
      "  Action items: 2, Recommendations: 4, Contentions: 1\n",
      "\n",
      "CSAS Transformation update-FR.pptx\n",
      "  Total rows: 61\n",
      "  Languages: {'fr': 37, 'unknown': 15, 'en': 8, 'ca': 1}\n",
      "  Action items: 3, Recommendations: 2, Contentions: 5\n",
      "\n",
      "CSAS Transformation update.pptx\n",
      "  Total rows: 61\n",
      "  Languages: {'en': 43, 'unknown': 15, 'hr': 1, 'it': 1, 'so': 1}\n",
      "  Action items: 13, Recommendations: 2, Contentions: 7\n",
      "\n",
      "Centralization of web and publication.docx\n",
      "  Total rows: 25\n",
      "  Languages: {'en': 24, 'fr': 1}\n",
      "  Action items: 4, Recommendations: 1, Contentions: 3\n",
      "\n",
      "Coordinators F2F Agenda.docx\n",
      "  Total rows: 60\n",
      "  Languages: {'en': 22, 'fr': 21, 'de': 7, 'sw': 4, 'nl': 2, 'tl': 2, 'id': 1, 'ro': 1}\n",
      "  Action items: 5, Recommendations: 2, Contentions: 2\n",
      "\n",
      "F2F Action Items.docx\n",
      "  Total rows: 18\n",
      "  Languages: {'en': 13, 'tl': 2, 'de': 1, 'it': 1, 'es': 1}\n",
      "  Action items: 1, Recommendations: 0, Contentions: 0\n",
      "\n",
      "F2F Meeting Notes (draft).docx\n",
      "  Total rows: 174\n",
      "  Languages: {'en': 147, 'de': 8, 'tl': 7, 'it': 3, 'ca': 2, 'af': 1, 'nl': 1, 'id': 1, 'hu': 1, 'vi': 1, 'fr': 1, 'pt': 1}\n",
      "  Action items: 39, Recommendations: 19, Contentions: 33\n",
      "\n",
      "F2F Meeting Report (near final).docx\n",
      "  Total rows: 173\n",
      "  Languages: {'en': 146, 'de': 8, 'tl': 7, 'it': 3, 'ca': 3, 'af': 1, 'nl': 1, 'vi': 1, 'id': 1, 'hu': 1, 'pt': 1}\n",
      "  Action items: 39, Recommendations: 19, Contentions: 33\n",
      "\n",
      "F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  Total rows: 173\n",
      "  Languages: {'fr': 147, 'de': 8, 'ca': 4, 'en': 3, 'ro': 2, 'it': 2, 'so': 2, 'pt': 2, 'sv': 1, 'hu': 1, 'tl': 1}\n",
      "  Action items: 1, Recommendations: 4, Contentions: 28\n",
      "\n",
      "Options and best practices for timely publication v2.docx\n",
      "  Total rows: 47\n",
      "  Languages: {'en': 43, 'fr': 2, 'de': 1, 'fi': 1}\n",
      "  Action items: 20, Recommendations: 10, Contentions: 7\n",
      "\n",
      "Process vs Product.pptx\n",
      "  Total rows: 15\n",
      "  Languages: {'en': 15}\n",
      "  Action items: 2, Recommendations: 3, Contentions: 5\n",
      "\n",
      "Survival exericise.pptx\n",
      "  Total rows: 32\n",
      "  Languages: {'fr': 16, 'en': 14, 'cy': 1, 'ca': 1}\n",
      "  Action items: 0, Recommendations: 0, Contentions: 0\n",
      "\n",
      "\n",
      "Cleaned data saved to meeting_data_cleaned.pkl and meeting_data_cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "c93q4ix3l08",
   "source": "## Phase 4: Iterative Refinement",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "bxljphryzc8",
   "source": "### Step 1: Resolve duplicate documents and create canonical versions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "kvie8sp02ep",
   "source": "print(\"=== DUPLICATE RESOLUTION ===\\n\")\n\n# Strategy 1: Handle F2F Meeting Report versions\n# Keep: \"F2F Meeting Report (near final)_TG_FR_LS_Final.docx\" (final version)\n# Remove: \"F2F Meeting Report (near final).docx\" (superseded)\n\nf2f_final = 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx'\nf2f_old = 'F2F Meeting Report (near final).docx'\n\nf2f_final_count = len(df_clean[df_clean['source_file'] == f2f_final])\nf2f_old_count = len(df_clean[df_clean['source_file'] == f2f_old])\n\nprint(\"Decision 1: F2F Meeting Report versions\")\nprint(f\"  Final version ({f2f_final}): {f2f_final_count} rows - KEEP\")\nprint(f\"  Older version ({f2f_old}): {f2f_old_count} rows - MARK FOR EXCLUSION\")\n\n# Strategy 2: Handle CSAS Transformation presentations\n# Keep both EN and FR, but mark as translation pair\ntrans_en = 'CSAS Transformation update.pptx'\ntrans_fr = 'CSAS Transformation update-FR.pptx'\n\ntrans_en_count = len(df_clean[df_clean['source_file'] == trans_en])\ntrans_fr_count = len(df_clean[df_clean['source_file'] == trans_fr])\n\nprint(\"\\nDecision 2: CSAS Transformation presentations\")\nprint(f\"  English version ({trans_en}): {trans_en_count} rows\")\nprint(f\"  French version ({trans_fr}): {trans_fr_count} rows\")\nprint(f\"  Action: KEEP BOTH, marked as translation pair\")\n\n# Create a version column indicating document status\ndf_clean['document_status'] = 'primary'\ndf_clean.loc[df_clean['source_file'] == f2f_old, 'document_status'] = 'superseded'\ndf_clean.loc[df_clean['source_file'].isin([trans_en, trans_fr]), 'document_status'] = 'primary_translated'\n\n# Create canonical source mapping\ncanonical_mapping = {\n    f2f_old: f2f_final,\n}\n\nprint(f\"\\n--- Document Status Distribution ---\")\nprint(df_clean['document_status'].value_counts())\n\nprint(f\"\\n--- Rows by status ---\")\nfor status in df_clean['document_status'].unique():\n    count = len(df_clean[df_clean['document_status'] == status])\n    files = df_clean[df_clean['document_status'] == status]['source_file'].unique()\n    print(f\"\\n{status.upper()}: {count} rows\")\n    for f in files:\n        print(f\"  - {f}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:35:15.653154Z",
     "start_time": "2025-11-19T13:35:15.639323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DUPLICATE RESOLUTION ===\n",
      "\n",
      "Decision 1: F2F Meeting Report versions\n",
      "  Final version (F2F Meeting Report (near final)_TG_FR_LS_Final.docx): 173 rows - KEEP\n",
      "  Older version (F2F Meeting Report (near final).docx): 173 rows - MARK FOR EXCLUSION\n",
      "\n",
      "Decision 2: CSAS Transformation presentations\n",
      "  English version (CSAS Transformation update.pptx): 61 rows\n",
      "  French version (CSAS Transformation update-FR.pptx): 61 rows\n",
      "  Action: KEEP BOTH, marked as translation pair\n",
      "\n",
      "--- Document Status Distribution ---\n",
      "document_status\n",
      "primary               567\n",
      "superseded            173\n",
      "primary_translated    122\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Rows by status ---\n",
      "\n",
      "PRIMARY: 567 rows\n",
      "  - Centralization of web and publication.docx\n",
      "  - Coordinators F2F Agenda.docx\n",
      "  - F2F Action Items.docx\n",
      "  - F2F Meeting Notes (draft).docx\n",
      "  - F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "  - Options and best practices for timely publication v2.docx\n",
      "  - CSAS Publications.pptx\n",
      "  - Process vs Product.pptx\n",
      "  - Survival exericise.pptx\n",
      "\n",
      "SUPERSEDED: 173 rows\n",
      "  - F2F Meeting Report (near final).docx\n",
      "\n",
      "PRIMARY_TRANSLATED: 122 rows\n",
      "  - CSAS Transformation update-FR.pptx\n",
      "  - CSAS Transformation update.pptx\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "gwsqw9mh0rc",
   "source": "### Step 2: Improve keyword detection for better categorization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "e0uqzl7au4u",
   "source": "# Refine keyword lists with context-aware matching\naction_keywords_refined = {\n    'explicit': ['action item', 'action:', 'to do', 'todo:', 'deliverable', 'deliver by'],\n    'responsibility': ['responsibility', 'responsible for', 'owner:', 'lead:', 'assigned to'],\n    'deadline': ['by:', 'deadline:', 'due date', 'due by', 'timeline', 'date:'],\n    'future_tense': ['will', 'shall', 'should', 'needs to', 'must', 'required to'],\n    'completion': ['implement', 'complete', 'finish', 'develop', 'create', 'establish']\n}\n\nrecommendation_keywords_refined = {\n    'recommendation': ['recommendation', 'recommend', 'we recommend'],\n    'best_practice': ['best practice', 'best practices', 'approach', 'option'],\n    'suggestion': ['suggest', 'propose', 'consider', 'should consider'],\n    'process': ['process', 'workflow', 'procedure', 'protocol']\n}\n\ncontention_keywords_refined = {\n    'concern': ['concern', 'issue', 'problem', 'risk', 'challenge'],\n    'conflict': ['disagreement', 'debate', 'conflict', 'tension'],\n    'unclear': ['unclear', 'undefined', 'pending', 'pending decision', 'to be determined'],\n    'discussion': ['discuss', 'discussion needed', 'needs discussion']\n}\n\ndef enhanced_keyword_check(text, keyword_dict):\n    text_lower = text.lower()\n    matches = []\n    for category, keywords in keyword_dict.items():\n        if any(kw in text_lower for kw in keywords):\n            matches.append(category)\n    return matches\n\n# Apply enhanced categorization\ndf_clean['action_categories'] = df_clean['text'].apply(\n    lambda x: enhanced_keyword_check(x, action_keywords_refined)\n)\ndf_clean['recommendation_categories'] = df_clean['text'].apply(\n    lambda x: enhanced_keyword_check(x, recommendation_keywords_refined)\n)\ndf_clean['contention_categories'] = df_clean['text'].apply(\n    lambda x: enhanced_keyword_check(x, contention_keywords_refined)\n)\n\n# Update boolean flags with more nuanced counts\ndf_clean['action_strength'] = df_clean['action_categories'].apply(len)\ndf_clean['recommendation_strength'] = df_clean['recommendation_categories'].apply(len)\ndf_clean['contention_strength'] = df_clean['contention_categories'].apply(len)\n\nprint(\"=== ENHANCED KEYWORD CATEGORIZATION ===\\n\")\n\nprint(\"Action items by strength:\")\nfor strength in sorted(df_clean['action_strength'].unique(), reverse=True):\n    count = (df_clean['action_strength'] == strength).sum()\n    print(f\"  Strength {strength}: {count} items\")\n\nprint(f\"\\nRecommendations by strength:\")\nfor strength in sorted(df_clean['recommendation_strength'].unique(), reverse=True):\n    count = (df_clean['recommendation_strength'] == strength).sum()\n    print(f\"  Strength {strength}: {count} items\")\n\nprint(f\"\\nContentions by strength:\")\nfor strength in sorted(df_clean['contention_strength'].unique(), reverse=True):\n    count = (df_clean['contention_strength'] == strength).sum()\n    print(f\"  Strength {strength}: {count} items\")\n\n# Show distribution of category matches\nprint(f\"\\n--- Category Distribution ---\")\nall_action_cats = []\nfor cats in df_clean['action_categories']:\n    all_action_cats.extend(cats)\nif all_action_cats:\n    from collections import Counter\n    print(\"Action categories found:\")\n    for cat, cnt in Counter(all_action_cats).most_common():\n        print(f\"  {cat}: {cnt}\")\n\nall_rec_cats = []\nfor cats in df_clean['recommendation_categories']:\n    all_rec_cats.extend(cats)\nif all_rec_cats:\n    print(\"\\nRecommendation categories found:\")\n    for cat, cnt in Counter(all_rec_cats).most_common():\n        print(f\"  {cat}: {cnt}\")\n\nall_cont_cats = []\nfor cats in df_clean['contention_categories']:\n    all_cont_cats.extend(cats)\nif all_cont_cats:\n    print(\"\\nContention categories found:\")\n    for cat, cnt in Counter(all_cont_cats).most_common():\n        print(f\"  {cat}: {cnt}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:35:15.738212Z",
     "start_time": "2025-11-19T13:35:15.715361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENHANCED KEYWORD CATEGORIZATION ===\n",
      "\n",
      "Action items by strength:\n",
      "  Strength 3: 5 items\n",
      "  Strength 2: 19 items\n",
      "  Strength 1: 96 items\n",
      "  Strength 0: 742 items\n",
      "\n",
      "Recommendations by strength:\n",
      "  Strength 3: 2 items\n",
      "  Strength 2: 27 items\n",
      "  Strength 1: 143 items\n",
      "  Strength 0: 690 items\n",
      "\n",
      "Contentions by strength:\n",
      "  Strength 2: 3 items\n",
      "  Strength 1: 121 items\n",
      "  Strength 0: 738 items\n",
      "\n",
      "--- Category Distribution ---\n",
      "Action categories found:\n",
      "  future_tense: 48\n",
      "  completion: 40\n",
      "  explicit: 32\n",
      "  deadline: 25\n",
      "  responsibility: 4\n",
      "\n",
      "Recommendation categories found:\n",
      "  process: 117\n",
      "  best_practice: 42\n",
      "  suggestion: 36\n",
      "  recommendation: 8\n",
      "\n",
      "Contention categories found:\n",
      "  discussion: 102\n",
      "  concern: 20\n",
      "  unclear: 3\n",
      "  conflict: 2\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "k9ea1n51g48",
   "source": "### Step 3: Validate improvements and identify remaining issues",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p0dk28nw6e",
   "source": "print(\"=== QUALITY VALIDATION & IMPROVEMENT ASSESSMENT ===\\n\")\n\n# Data integrity checks\nprint(\"--- Data Integrity ---\")\nprint(f\"Total rows: {len(df_clean)}\")\nprint(f\"Null values: {df_clean.isnull().sum().sum()}\")\nprint(f\"Unique documents: {df_clean['source_file'].nunique()}\")\nprint(f\"Language coverage: {df_clean['language'].nunique()} languages detected\")\n\n# Completeness check\nprint(f\"\\n--- Completeness Check ---\")\nprint(f\"Rows with language detected: {(df_clean['language'] != 'unknown').sum()} ({(df_clean['language'] != 'unknown').sum()/len(df_clean)*100:.1f}%)\")\nprint(f\"Rows categorized as action items: {df_clean['action_strength'].gt(0).sum()}\")\nprint(f\"Rows categorized as recommendations: {df_clean['recommendation_strength'].gt(0).sum()}\")\nprint(f\"Rows categorized as contentions: {df_clean['contention_strength'].gt(0).sum()}\")\n\n# Document status check\nprint(f\"\\n--- Document Status Validation ---\")\nprimary_count = (df_clean['document_status'] == 'primary').sum()\nsuperseded_count = (df_clean['document_status'] == 'superseded').sum()\ntranslated_count = (df_clean['document_status'] == 'primary_translated').sum()\n\nprint(f\"Primary documents: {primary_count} rows\")\nprint(f\"Superseded documents: {superseded_count} rows (flagged for exclusion)\")\nprint(f\"Primary translated pairs: {translated_count} rows\")\n\n# Identify potential issues\nprint(f\"\\n--- Potential Data Quality Issues ---\")\n\n# Mixed language in single document\nprint(\"\\n1. Documents with mixed languages:\")\nfor source_file in df_clean['source_file'].unique():\n    subset = df_clean[df_clean['source_file'] == source_file]\n    langs = subset['language'].unique()\n    if len(langs) > 1 and 'unknown' not in langs:\n        lang_dist = subset['language'].value_counts()\n        print(f\"   {source_file}\")\n        for lang, count in lang_dist.items():\n            if lang != 'unknown':\n                print(f\"     {lang}: {count} rows\")\n\n# Very short entries that might be formatting\nprint(\"\\n2. Very short entries (potential formatting artifacts):\")\nshort = df_clean[df_clean['text'].str.len() < 5]\nif len(short) > 0:\n    print(f\"   Found {len(short)} entries with <5 characters\")\n    print(f\"   Examples: {short['text'].unique()[:5]}\")\nelse:\n    print(\"   None found\")\n\n# Elements with no categorization\nprint(\"\\n3. Uncategorized rows (no action/recommendation/contention signals):\")\nuncategorized = df_clean[(df_clean['action_strength'] == 0) & \n                          (df_clean['recommendation_strength'] == 0) & \n                          (df_clean['contention_strength'] == 0)]\nprint(f\"   {len(uncategorized)} rows have no content signals ({len(uncategorized)/len(df_clean)*100:.1f}%)\")\n\n# Files with low action item count (might need review)\nprint(\"\\n4. Files with low action item extraction:\")\nfile_actions = df_clean.groupby('source_file')['action_strength'].apply(lambda x: (x > 0).sum())\nfor source_file, count in file_actions.items():\n    if count == 0 and 'Publications' not in source_file and 'Survival' not in source_file:\n        print(f\"   {source_file}: {count} action items\")\n\nprint(\"\\n--- Overall Assessment ---\")\nprint(f\"Data quality: GOOD (no nulls, comprehensive categorization)\")\nprint(f\"Recommended action: Proceed to Phase 5 (Quality Assessment)\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:35:15.764091Z",
     "start_time": "2025-11-19T13:35:15.742815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUALITY VALIDATION & IMPROVEMENT ASSESSMENT ===\n",
      "\n",
      "--- Data Integrity ---\n",
      "Total rows: 862\n",
      "Null values: 0\n",
      "Unique documents: 12\n",
      "Language coverage: 22 languages detected\n",
      "\n",
      "--- Completeness Check ---\n",
      "Rows with language detected: 832 (96.5%)\n",
      "Rows categorized as action items: 120\n",
      "Rows categorized as recommendations: 172\n",
      "Rows categorized as contentions: 124\n",
      "\n",
      "--- Document Status Validation ---\n",
      "Primary documents: 567 rows\n",
      "Superseded documents: 173 rows (flagged for exclusion)\n",
      "Primary translated pairs: 122 rows\n",
      "\n",
      "--- Potential Data Quality Issues ---\n",
      "\n",
      "1. Documents with mixed languages:\n",
      "   Centralization of web and publication.docx\n",
      "     en: 24 rows\n",
      "     fr: 1 rows\n",
      "   Coordinators F2F Agenda.docx\n",
      "     en: 22 rows\n",
      "     fr: 21 rows\n",
      "     de: 7 rows\n",
      "     sw: 4 rows\n",
      "     nl: 2 rows\n",
      "     tl: 2 rows\n",
      "     id: 1 rows\n",
      "     ro: 1 rows\n",
      "   F2F Action Items.docx\n",
      "     en: 13 rows\n",
      "     tl: 2 rows\n",
      "     de: 1 rows\n",
      "     it: 1 rows\n",
      "     es: 1 rows\n",
      "   F2F Meeting Notes (draft).docx\n",
      "     en: 147 rows\n",
      "     de: 8 rows\n",
      "     tl: 7 rows\n",
      "     it: 3 rows\n",
      "     ca: 2 rows\n",
      "     af: 1 rows\n",
      "     nl: 1 rows\n",
      "     id: 1 rows\n",
      "     hu: 1 rows\n",
      "     vi: 1 rows\n",
      "     fr: 1 rows\n",
      "     pt: 1 rows\n",
      "   F2F Meeting Report (near final).docx\n",
      "     en: 146 rows\n",
      "     de: 8 rows\n",
      "     tl: 7 rows\n",
      "     it: 3 rows\n",
      "     ca: 3 rows\n",
      "     af: 1 rows\n",
      "     nl: 1 rows\n",
      "     vi: 1 rows\n",
      "     id: 1 rows\n",
      "     hu: 1 rows\n",
      "     pt: 1 rows\n",
      "   F2F Meeting Report (near final)_TG_FR_LS_Final.docx\n",
      "     fr: 147 rows\n",
      "     de: 8 rows\n",
      "     ca: 4 rows\n",
      "     en: 3 rows\n",
      "     ro: 2 rows\n",
      "     it: 2 rows\n",
      "     so: 2 rows\n",
      "     pt: 2 rows\n",
      "     sv: 1 rows\n",
      "     hu: 1 rows\n",
      "     tl: 1 rows\n",
      "   Options and best practices for timely publication v2.docx\n",
      "     en: 43 rows\n",
      "     fr: 2 rows\n",
      "     de: 1 rows\n",
      "     fi: 1 rows\n",
      "   CSAS Publications.pptx\n",
      "     en: 15 rows\n",
      "     de: 2 rows\n",
      "     fr: 2 rows\n",
      "     nl: 1 rows\n",
      "     tl: 1 rows\n",
      "     no: 1 rows\n",
      "     ro: 1 rows\n",
      "   Survival exericise.pptx\n",
      "     fr: 16 rows\n",
      "     en: 14 rows\n",
      "     cy: 1 rows\n",
      "     ca: 1 rows\n",
      "\n",
      "2. Very short entries (potential formatting artifacts):\n",
      "   Found 32 entries with <5 characters\n",
      "   Examples: ['Data' '1' '2' '3' '4']\n",
      "\n",
      "3. Uncategorized rows (no action/recommendation/contention signals):\n",
      "   560 rows have no content signals (65.0%)\n",
      "\n",
      "4. Files with low action item extraction:\n",
      "\n",
      "--- Overall Assessment ---\n",
      "Data quality: GOOD (no nulls, comprehensive categorization)\n",
      "Recommended action: Proceed to Phase 5 (Quality Assessment)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "8rdrynejvql",
   "source": "### Step 4: Export refined dataset and log decisions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "58e5zobkytu",
   "source": "# Create decision log\ndecisions = [\n    {\n        'decision': 'Exclude superseded F2F Meeting Report version',\n        'reasoning': 'F2F Meeting Report (near final)_TG_FR_LS_Final.docx is the final approved version',\n        'files_affected': ['F2F Meeting Report (near final).docx'],\n        'rows_affected': int(superseded_count),\n        'status': 'marked_as_superseded'\n    },\n    {\n        'decision': 'Keep both EN/FR Transformation presentations',\n        'reasoning': 'Both provide translation coverage for the same content',\n        'files_affected': ['CSAS Transformation update.pptx', 'CSAS Transformation update-FR.pptx'],\n        'rows_affected': int(translated_count),\n        'status': 'marked_as_translation_pair'\n    },\n    {\n        'decision': 'Enhanced keyword categorization',\n        'reasoning': 'Context-aware keyword matching with strength scoring improves accuracy',\n        'files_affected': ['all'],\n        'rows_affected': int(len(df_clean)),\n        'status': 'applied'\n    },\n    {\n        'decision': 'Language detection applied',\n        'reasoning': 'Langdetect used to identify French vs English content for filtering',\n        'files_affected': ['all'],\n        'rows_affected': int(len(df_clean)),\n        'status': 'applied'\n    }\n]\n\ndecision_log_df = pd.DataFrame(decisions)\n\nprint(\"=== PHASE 4 DECISION LOG ===\\n\")\nfor idx, decision in enumerate(decisions, 1):\n    print(f\"{idx}. {decision['decision']}\")\n    print(f\"   Reasoning: {decision['reasoning']}\")\n    print(f\"   Status: {decision['status']}\")\n    print()\n\n# Export datasets\nprint(\"=== EXPORTING REFINED DATA ===\\n\")\n\n# Full refined dataset\ndf_clean.to_pickle('meeting_data_refined.pkl')\ndf_clean.to_csv('meeting_data_refined.csv', index=False)\nprint(\"✓ Exported: meeting_data_refined.pkl\")\nprint(\"✓ Exported: meeting_data_refined.csv\")\n\n# Dataset with only primary documents (excluding superseded)\ndf_primary = df_clean[df_clean['document_status'] != 'superseded'].copy()\ndf_primary.to_pickle('meeting_data_primary.pkl')\ndf_primary.to_csv('meeting_data_primary.csv', index=False)\nprint(f\"✓ Exported: meeting_data_primary.pkl ({len(df_primary)} rows)\")\nprint(f\"✓ Exported: meeting_data_primary.csv\")\n\n# Decision log\ndecision_log_df.to_csv('phase4_decision_log.csv', index=False)\nprint(\"✓ Exported: phase4_decision_log.csv\")\n\n# Create summary metrics (convert int64 to int for JSON serialization)\nmetrics = {\n    'total_rows_refined': int(len(df_clean)),\n    'total_rows_primary': int(len(df_primary)),\n    'rows_excluded': int(len(df_clean) - len(df_primary)),\n    'documents_processed': int(df_clean['source_file'].nunique()),\n    'languages_detected': int(df_clean['language'].nunique()),\n    'action_items': int(df_clean['action_strength'].gt(0).sum()),\n    'recommendations': int(df_clean['recommendation_strength'].gt(0).sum()),\n    'contentions': int(df_clean['contention_strength'].gt(0).sum()),\n    'extraction_rate': f\"{(df_clean['language'] != 'unknown').sum()/len(df_clean)*100:.1f}%\"\n}\n\nprint(f\"\\n--- Phase 4 Summary Metrics ---\")\nfor key, value in metrics.items():\n    print(f\"{key}: {value}\")\n\n# Save metrics\nimport json\nwith open('phase4_metrics.json', 'w') as f:\n    json.dump(metrics, f, indent=2)\nprint(\"\\n✓ Exported: phase4_metrics.json\")\n\nprint(f\"\\nPhase 4: Iterative Refinement COMPLETED\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T13:36:53.945664Z",
     "start_time": "2025-11-19T13:36:53.915397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 4 DECISION LOG ===\n",
      "\n",
      "1. Exclude superseded F2F Meeting Report version\n",
      "   Reasoning: F2F Meeting Report (near final)_TG_FR_LS_Final.docx is the final approved version\n",
      "   Status: marked_as_superseded\n",
      "\n",
      "2. Keep both EN/FR Transformation presentations\n",
      "   Reasoning: Both provide translation coverage for the same content\n",
      "   Status: marked_as_translation_pair\n",
      "\n",
      "3. Enhanced keyword categorization\n",
      "   Reasoning: Context-aware keyword matching with strength scoring improves accuracy\n",
      "   Status: applied\n",
      "\n",
      "4. Language detection applied\n",
      "   Reasoning: Langdetect used to identify French vs English content for filtering\n",
      "   Status: applied\n",
      "\n",
      "=== EXPORTING REFINED DATA ===\n",
      "\n",
      "✓ Exported: meeting_data_refined.pkl\n",
      "✓ Exported: meeting_data_refined.csv\n",
      "✓ Exported: meeting_data_primary.pkl (689 rows)\n",
      "✓ Exported: meeting_data_primary.csv\n",
      "✓ Exported: phase4_decision_log.csv\n",
      "\n",
      "--- Phase 4 Summary Metrics ---\n",
      "total_rows_refined: 862\n",
      "total_rows_primary: 689\n",
      "rows_excluded: 173\n",
      "documents_processed: 12\n",
      "languages_detected: 22\n",
      "action_items: 120\n",
      "recommendations: 172\n",
      "contentions: 124\n",
      "extraction_rate: 96.5%\n",
      "\n",
      "✓ Exported: phase4_metrics.json\n",
      "\n",
      "Phase 4: Iterative Refinement COMPLETED\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "87e222c66a74fb8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
